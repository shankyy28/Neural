{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 04:44:19.158414: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1579 - accuracy: 0.9537\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0571 - accuracy: 0.9825\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0362 - accuracy: 0.9887\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0241 - accuracy: 0.9926\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0176 - accuracy: 0.9944\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.0131 - accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0091 - accuracy: 0.9972\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0047 - accuracy: 0.9984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x135beaed0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the required libraries\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#loading data\n",
    "(X_train,y_train) , (X_test,y_test)=mnist.load_data()\n",
    "\n",
    "#reshaping data\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2],1))\n",
    "\n",
    "#checking the shape after reshaping\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#normalizing the pixel values\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "\n",
    "#defining model\n",
    "model=Sequential()\n",
    "\n",
    "#adding convolution layer\n",
    "model.add(Conv2D(32,(3,3),activation= \"relu\",input_shape=(28,28,1)))\n",
    "\n",
    "#adding pooling layer\n",
    "model.add(MaxPool2D(2,2))\n",
    "\n",
    "#adding fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation=\"relu\"))\n",
    "\n",
    "#adding output layer\n",
    "model.add(Dense(10,activation= \"softmax\" ))\n",
    "\n",
    "#compiling the model\n",
    "model.compile(loss= \"sparse_categorical_crossentropy\",optimizer= \"adam\",metrics=[\"accuracy\"])\n",
    "#fitting the model\n",
    "model.fit(X_train,y_train,epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data.dataloader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gray = 0.1307\n",
    "stddev_gray= 0.3081\n",
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize((mean_gray),(stddev_gray))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "train_dataset= datasets.MNIST(root='./data', train = True, transform=transforms, download=True)\n",
    "test_dataset= datasets.MNIST(root='./data', train = False, transform=transforms, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x163536110>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize(denormalise)\n",
    "\n",
    "random_img=train_dataset[20][0].numpy() * stddev_gray + mean_gray\n",
    "plt.imshow(random_img.reshape(28,28),cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "label = train_dataset[20][1]  # Getting the label from the dataset\n",
    "print(label)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "\n",
    "# Creating DataLoaders for training and testing\n",
    "train_load = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_load = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 images in the training set\n",
      "There are 10000 images in the test set\n",
      "There are 600 batches in the train loader\n",
      "There are 100 batches in the testloader\n"
     ]
    }
   ],
   "source": [
    "print('There are {} images in the training set'.format(len(train_dataset)))\n",
    "print('There are {} images in the test set'.format(len(test_dataset)))\n",
    "print('There are {} batches in the train loader'.format(len(train_load)))\n",
    "print('There are {} batches in the testloader'.format(len(test_load)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self) \n",
    "        self.cnn1= nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm1= nn.BatchNorm2d\n",
    "        self.relu= nn.ReLU()\n",
    "        self.maxpool= nn.MaxPool2d(kernel_size=2)\n",
    "        self.maxpool = nn.MaxPool2d(Kernel_size = 2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels = 8, out_channels = 32, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(1568,600)    #fully connected layer\n",
    "        self.dropout = nn.dropout(0.5)\n",
    "        self.fc2 = nn.Linear(600,10)      #fully connected layer\n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.view(-1,1568)  #1568=7X7X32\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3895314227.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[53], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    optimizer = torch.optim.SGD(model.parameters(), lr = 0.0\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model = model.cuda()    \n",
    "loss_fn = nn.CrossEntropyLoss()        \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
